# --- ResNet_focal_loss.py (Model V2.5 - å®Œæ•´ K-Fold è®­ç»ƒç‰ˆ) ---

import torch
import os
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
import copy
import numpy as np
import pandas as pd
import torch.nn.functional as F
import torchvision.transforms as transforms
from sklearn.model_selection import StratifiedKFold
from torch.optim import lr_scheduler
# --- è¯„ä¼°æŒ‡æ ‡åº“ ---
from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from matplotlib import font_manager, rcParams
from sklearn.utils import resample
from typing import Dict, Any, List, Tuple

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— (å‡è®¾è¿™äº›æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹)
# ğŸš¨ ç¡®ä¿æ‚¨çš„ dataloader.py, cbam_model.py, resnet_fusion_v25.py æ–‡ä»¶å­˜åœ¨
from dataloader import imgDataset
from resnet_fusion_v25 import ResNetSAM_TabularFusion

# ----------------------------------------------------------------------
# 0. æ–‡ä»¶è·¯å¾„å’Œå‚æ•°å®šä¹‰
# ----------------------------------------------------------------------
# ğŸš¨ è¯·æ ¹æ®æ‚¨çš„å®é™…è·¯å¾„å’Œå‚æ•°è¿›è¡Œæ£€æŸ¥å’Œä¿®æ”¹
CHECKPOINT_FILE = "kfold_checkpoint_V25_fusion_AllData.pt"
BEST_MODEL_WTS_FILE = "best_kfold_model_V25_fusion_AllData.pth"
KFOLD_SUMMARY_FILE = "kfold_summary_V25_fusion_AllData.txt"
# ğŸš¨ ã€æ–°å¢ã€‘DeLong æ£€éªŒæ•°æ®ä¿å­˜æ–‡ä»¶
DELONG_DATA_FILE = "patient_level_fusion_V25_training_run_delong.csv"
# è¡¨æ ¼ç‰¹å¾æ•°é‡ (å°†ä» dataloader ä¸­è·å–)
NUM_TABULAR_FEATURES = 20


# ----------------------------------------------------------------------
# 1. Focal Loss å®šä¹‰ (æŸå¤±å‡½æ•°)
# ----------------------------------------------------------------------
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2, num_classes=3, size_average=True):
        super(FocalLoss, self).__init__()
        self.size_average = size_average
        if alpha is None:
            self.alpha = torch.ones(num_classes)
        elif isinstance(alpha, list):
            assert len(alpha) == num_classes
            self.alpha = torch.Tensor(alpha)
        else:
            assert alpha < 1
            self.alpha = torch.zeros(num_classes)
            self.alpha[0] += alpha
            self.alpha[1:] += (1 - alpha)
        self.gamma = gamma

    def forward(self, preds, labels):
        preds = preds.view(-1, preds.size(-1))
        labels = labels.view(-1, 1)
        device = labels.device
        alpha = self.alpha.to(device)

        preds_logsoft = F.log_softmax(preds, dim=1)
        preds_softmax = torch.exp(preds_logsoft)

        preds_softmax = preds_softmax.gather(1, labels)
        preds_logsoft = preds_logsoft.gather(1, labels)
        alpha = alpha.gather(0, labels.view(-1))

        focal_weight = torch.pow((1 - preds_softmax), self.gamma)
        focal_loss = -torch.mul(focal_weight, preds_logsoft)
        loss = torch.mul(alpha, focal_loss.t())

        if self.size_average:
            loss = loss.mean()
        else:
            loss = loss.sum()
        return loss


# ----------------------------------------------------------------------
# 2. è®­ç»ƒå’Œæµ‹è¯•å‡½æ•°
# ----------------------------------------------------------------------
def train_model_fold(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=30):
    """K-Fold å†…éƒ¨è®­ç»ƒå‡½æ•°"""
    best_model_wts = copy.deepcopy(model.state_dict())
    best_loss = 1e9

    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss = 0.0

        # dataloader: img, info, masks(å¿½ç•¥), target, patient_id
        for img, info, _, target, _ in dataloaders['train']:
            inputs = img.to(device)
            info = info.to(device).float()
            labels = target.to(device)

            optimizer.zero_grad()
            outputs = model(inputs, info)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

        scheduler.step()
        epoch_loss = running_loss / dataset_sizes['train']

        # éªŒè¯é˜¶æ®µ (åªè®°å½•æœ€ä½³æ¨¡å‹ï¼Œä¸å½±å“è®­ç»ƒ)
        model.eval()
        val_running_loss = 0.0
        with torch.no_grad():
            for img, info, _, target, _ in dataloaders['val']:
                inputs = img.to(device)
                info = info.to(device).float()
                labels = target.to(device)
                outputs = model(inputs, info)
                loss = criterion(outputs, labels)
                val_running_loss += loss.item() * inputs.size(0)

        val_loss = val_running_loss / dataset_sizes['val']

        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss: {epoch_loss:.4f} Val Loss: {val_loss:.4f}')

        # è®°å½•æœ€ä½³æƒé‡
        if val_loss < best_loss:
            best_loss = val_loss
            best_model_wts = copy.deepcopy(model.state_dict())

    return best_model_wts, best_loss


def test_model_fold(model, dataloader, num_classes, device) -> Tuple[torch.Tensor, pd.DataFrame]:
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½å¹¶è¿”å›å›¾åƒçº§æŒ‡æ ‡ä»¥åŠç”¨äºæ‚£è€…çº§èšåˆçš„ DataFrameã€‚"""
    model.eval()

    fold_data_list = []
    running_corrects = 0
    dataset_size = len(dataloader.dataset)

    with torch.no_grad():
        for img, info, _, target, patient_ids in dataloader:
            inputs = img.to(device)
            info = info.to(device).float()
            labels = target.to(device)

            outputs = model(inputs, info)
            probas = F.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)

            running_corrects += torch.sum(preds == labels.data)

            probas_np = probas.cpu().numpy()
            labels_np = labels.cpu().numpy()
            preds_np = preds.cpu().numpy()

            # å‡†å¤‡æ‚£è€…çº§èšåˆæ•°æ®
            for i in range(len(patient_ids)):
                fold_data_list.append({
                    'PatientID': patient_ids[i],
                    'TrueLabel': labels_np[i],
                    'PredLabel_Image': preds_np[i],
                    'Prob_0': probas_np[i, 0],
                    'Prob_1': probas_np[i, 1],
                    'Prob_2': probas_np[i, 2],
                })

    image_acc = running_corrects.double() / dataset_size
    fold_df = pd.DataFrame(fold_data_list)

    return image_acc, fold_df


# ----------------------------------------------------------------------
# 3. ç»“æœèšåˆå’ŒæŒ‡æ ‡è®¡ç®—å‡½æ•° (ä¿æŒä¸å˜)
# ----------------------------------------------------------------------
def aggregate_patient_results(df, num_classes=3, aggregation_method='max_prob'):
    # ... (æ­¤å‡½æ•°å®ç°ä¸åŸæ–‡ä»¶ä¸€è‡´) ...
    if aggregation_method == 'max_prob':
        patient_agg_df = df.groupby('PatientID')[['Prob_0', 'Prob_1', 'Prob_2']].max().reset_index()
    else:
        patient_agg_df = df.groupby('PatientID')[['Prob_0', 'Prob_1', 'Prob_2']].mean().reset_index()

    true_labels_df = df.groupby('PatientID')['TrueLabel'].first().reset_index()
    patient_agg_df = pd.merge(patient_agg_df, true_labels_df, on='PatientID')

    prob_cols = ['Prob_0', 'Prob_1', 'Prob_2']
    patient_agg_df['PredLabel'] = patient_agg_df[prob_cols].values.argmax(axis=1)

    true_labels = patient_agg_df['TrueLabel'].tolist()
    pred_labels = patient_agg_df['PredLabel'].tolist()
    probas = patient_agg_df[prob_cols].values

    patient_acc = accuracy_score(true_labels, pred_labels)
    cm = confusion_matrix(true_labels, pred_labels, labels=list(range(num_classes)))
    report = classification_report(true_labels, pred_labels, digits=4, output_dict=True, zero_division=0)

    return patient_acc, cm, report, true_labels, probas, patient_agg_df


def bootstrap_ci(y_true, y_pred, n_iterations=1000, alpha=0.05):
    # ... (æ­¤å‡½æ•°å®ç°ä¸åŸæ–‡ä»¶ä¸€è‡´) ...
    accuracies = []
    data = np.array(list(zip(y_true, y_pred)))

    if len(data) < 20:
        return None, None

    for _ in range(n_iterations):
        sample = resample(data, replace=True, n_samples=len(data))
        y_true_sample = sample[:, 0]
        y_pred_sample = sample[:, 1]

        acc = accuracy_score(y_true_sample, y_pred_sample)
        accuracies.append(acc)

    p = ((alpha / 2.0) * 100)
    lower = np.percentile(accuracies, p)
    p = (100 - (alpha / 2.0) * 100)
    upper = np.percentile(accuracies, p)

    return lower, upper


def print_metrics(name, image_acc, patient_acc, cm, report, probas, labels, num_classes, class_names_short,
                  output_file=None, ci_bounds=None):
    # ... (æ­¤å‡½æ•°å®ç°ä¸åŸæ–‡ä»¶ä¸€è‡´) ...
    output = []

    def log_print(msg):
        print(msg)
        output.append(msg)

    log_print(f"\n==================== {name} æ€§èƒ½æŠ¥å‘Š ====================")
    log_print(f"å›¾åƒçº§å‡†ç¡®ç‡: {image_acc:.4f}")

    ci_str = f"({ci_bounds[0]:.4f}, {ci_bounds[1]:.4f})" if ci_bounds and ci_bounds[0] is not None else ""
    log_print(f"æ‚£è€…çº§å‡†ç¡®ç‡: {patient_acc:.4f} (æ€»è®¡ {len(labels)} ä¾‹) {ci_str}")

    y_true_binarized = label_binarize(labels, classes=list(range(num_classes)))
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], probas[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])
        log_print(f"  {class_names_short[i]} AUC: {roc_auc[i]:.4f}")

    log_print("\næ‚£è€…çº§è¯¦ç»†åˆ†ç±»æŠ¥å‘Š (Precision, Recall, F1-Score):")
    report_str = pd.DataFrame(report).transpose().to_string(float_format='%.4f')
    log_print(report_str)

    log_print("\næ‚£è€…çº§æ··æ·†çŸ©é˜µ (Confusion Matrix):")
    log_print(str(pd.DataFrame(cm, index=class_names_short, columns=class_names_short)))
    log_print("========================================================\n")

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(output))

        # ç»˜åˆ¶ ROC æ›²çº¿å¹¶ä¿å­˜
        plt.figure(figsize=(10, 7))
        colors = ['#1f77b4', '#2ca02c', '#d62728']
        for i, color in zip(range(num_classes), colors):
            plt.plot(fpr[i], tpr[i], color=color, lw=2,
                     label=f'{class_names_short[i]} (AUC = {roc_auc[i]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='éšæœºçŒœæµ‹ (AUC = 0.50)')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å‡æ­£ç‡ (False Positive Rate)')
        plt.ylabel('çœŸæ­£ç‡ (True Positive Rate)')
        plt.title(f'{name} æ‚£è€…çº§ ROC æ›²çº¿ (One-vs-Rest)')
        plt.legend(loc="lower right")
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.savefig(output_file.replace('.txt', '_ROC.png'))
        plt.close()
        log_print(f"--- {name} ROC æ›²çº¿å›¾å·²ä¿å­˜ä¸º {output_file.replace('.txt', '_ROC.png')} ---")


# ----------------------------------------------------------------------
# 4. ä¸»ç¨‹åºå— (Main)
# ----------------------------------------------------------------------
if __name__ == '__main__':
    # ğŸš¨ è¯·æ£€æŸ¥è¿™äº›å‚æ•°æ˜¯å¦ä¸æ‚¨è®­ç»ƒæ—¶çš„è®¾ç½®ä¸€è‡´
    data_dir = 'D://' # Please change this path to your local data directory
    batch_size = 16
    num_classes = 3
    num_epochs = 30  # K-Fold æ¯ä¸ªæŠ˜å çš„è®­ç»ƒè½®æ•°
    K = 5
    class_names_short = ['æ…¢æ€§é˜‘å°¾ç‚', 'æ…¢å‘æ€¥', 'æ€¥æ€§é˜‘å°¾ç‚']

    # å®šä¹‰æ•°æ®è½¬æ¢ (ä¿æŒä¸å˜)
    data_transforms = {
        'train': transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomVerticalFlip(),
            transforms.ToTensor(),
        ]),
        'val': transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ]),
    }

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # --- Matplotlib ä¸­æ–‡æ˜¾ç¤ºä¿®å¤ (ä¿æŒä¸å˜) ---
    # ... (Matplotlib ä¸­æ–‡é…ç½®ä»£ç ) ...
    try:
        font_path = None
        for font in font_manager.findSystemFonts(fontpaths=None, fontext='ttf'):
            if 'simhei' in font.lower():
                font_path = font
                break
        if font_path:
            font_manager.fontManager.addfont(font_path)
            rcParams['font.family'] = 'SimHei'
            rcParams['axes.unicode_minus'] = False
        # ... (çœç•¥æ‰“å°ä¿¡æ¯) ...
    except Exception as e:
        # ... (çœç•¥é”™è¯¯ä¿¡æ¯) ...
        pass
    # ------------------------------------------------

    # 1. åŠ è½½æ‰€æœ‰æ•°æ®
    full_dataset = imgDataset(split='full', transform=data_transforms['train'])
    NUM_TABULAR_FEATURES = full_dataset.NUM_TABULAR_FEATURES  # ä» dataloader è·å–ç‰¹å¾æ•°

    print(f"æ‰€æœ‰æ•°æ® (K-Fold æ€»æ± ) å›¾åƒæ•°: {len(full_dataset.fnames)}")

    all_indices = list(range(len(full_dataset.fnames)))
    all_labels = np.array([item[2] for item in full_dataset.fnames])

    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)
    splits = list(skf.split(all_indices, all_labels))

    fold_image_accuracies: List[float] = []
    all_fold_df = pd.DataFrame()
    best_val_loss_global = 1e9
    best_model_wts_global = None

    # Focal Loss å‚æ•°
    alpha = [0.28, 0.58, 0.14]  # å‡è®¾æ‚¨ä½¿ç”¨è¿™äº›æƒé‡
    criterion = FocalLoss(alpha=alpha, gamma=2)

    # 2. K-Fold å¾ªç¯
    for fold in range(K):
        train_index, val_index = splits[fold]

        print(f"\n==================== Fold {fold + 1}/{K} è®­ç»ƒ ====================")

        # å‡†å¤‡æ•°æ®é›†å’Œ DataLoader
        train_dataset = Subset(full_dataset, train_index)
        val_dataset = Subset(full_dataset, val_index)

        dataloaders = {
            'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0),
            'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
        }
        dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}

        # å®ä¾‹åŒ–æ–°çš„èåˆæ¨¡å‹
        model = ResNetSAM_TabularFusion(num_classes, num_tabular=NUM_TABULAR_FEATURES)
        model = model.to(device)
        optimizer = optim.Adam(model.parameters(), lr=0.00005)
        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

        # è®­ç»ƒè¯¥æŠ˜å 
        best_wts, best_loss_fold = train_model_fold(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes,
                                                    device,
                                                    num_epochs=num_epochs)

        # æµ‹è¯•è¯¥æŠ˜å çš„æœ€ä½³æ¨¡å‹
        model.load_state_dict(best_wts)
        fold_acc_tensor, fold_df = test_model_fold(
            model, dataloaders['val'], num_classes, device
        )

        # è®°å½•ç»“æœ
        fold_acc = fold_acc_tensor.item()
        fold_image_accuracies.append(fold_acc)
        if not fold_df.empty:
            all_fold_df = pd.concat([all_fold_df, fold_df], ignore_index=True)

        print(f"Fold {fold + 1} éªŒè¯é›†å›¾åƒçº§å‡†ç¡®ç‡: {fold_acc:.4f}")

        # è®°å½•å…¨å±€æœ€ä½³æƒé‡
        if best_loss_fold < best_val_loss_global:
            best_val_loss_global = best_loss_fold
            best_model_wts_global = best_wts
            torch.save(best_model_wts_global, BEST_MODEL_WTS_FILE)
            print(f"--- å‘ç°æ–°çš„å…¨å±€æœ€ä½³æ¨¡å‹æƒé‡ï¼Œå·²ä¿å­˜åˆ° {BEST_MODEL_WTS_FILE} ---")

        # æ£€æŸ¥ç‚¹ä¿å­˜ï¼ˆå¯é€‰ï¼‰
        torch.save({
            'fold': fold,
            'best_val_loss_global': best_val_loss_global,
            'best_model_wts_global': best_model_wts_global,
            'fold_image_accuracies': fold_image_accuracies,
            'all_fold_df': all_fold_df,
        }, CHECKPOINT_FILE)

    # ----------------------------------------------------
    # 3. æ±‡æ€» K-Fold ç»“æœ (æœ€ç»ˆç»“æœ)
    # ----------------------------------------------------
    if not all_fold_df.empty:
        print("\n\n=======================================================")
        print("--- ALL DATA 5-Fold äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ (Max Prob Patient Aggregation) ---")
        mean_image_accuracy = np.mean(fold_image_accuracies)
        std_image_accuracy = np.std(fold_image_accuracies)
        print(f"å¹³å‡å›¾åƒçº§å‡†ç¡®ç‡ (Mean Image Accuracy): {mean_image_accuracy:.4f} Â± {std_image_accuracy:.4f}")

        patient_acc_kfold, cm_kfold, report_kfold, labels_kfold, probas_kfold, agg_df_kfold = aggregate_patient_results(
            all_fold_df, aggregation_method='max_prob'
        )

        # è®¡ç®— CI
        ci_lower, ci_upper = bootstrap_ci(agg_df_kfold['TrueLabel'].tolist(), agg_df_kfold['PredLabel'].tolist())
        ci_bounds = (ci_lower, ci_upper) if ci_lower is not None else None

        # ğŸš¨ ã€æ ¸å¿ƒä¿®æ”¹ï¼šä¿å­˜ DeLong æ£€éªŒæ•°æ®ã€‘
        try:
            # åªä¿å­˜è¿›è¡Œ DeLong æ£€éªŒå¿…éœ€çš„åˆ—
            agg_df_kfold[['PatientID', 'TrueLabel', 'Prob_0', 'Prob_1', 'Prob_2']].to_csv(DELONG_DATA_FILE, index=False,
                                                                                          encoding='utf-8')
            print(f"\n--- ğŸ¥³ æ‚£è€…çº§æ¦‚ç‡æ•°æ®å·²ä¿å­˜åˆ° {DELONG_DATA_FILE}ï¼Œå¯ç”¨äº DeLong æ£€éªŒã€‚ ---")
        except Exception as e:
            print(f"ğŸš¨ è­¦å‘Š: ä¿å­˜æ‚£è€…çº§æ¦‚ç‡æ•°æ®å¤±è´¥: {e}")

        # æ‰“å°å¹¶ä¿å­˜æ€§èƒ½æŠ¥å‘Šå’Œ ROC æ›²çº¿å›¾
        print_metrics("K-Fold äº¤å‰éªŒè¯æ±‡æ€» (Model V2.5 Fusion, All Data)",
                      mean_image_accuracy, patient_acc_kfold, cm_kfold, report_kfold, probas_kfold, labels_kfold,
                      num_classes, class_names_short, output_file=KFOLD_SUMMARY_FILE, ci_bounds=ci_bounds)

    # è®­ç»ƒç»“æŸåï¼Œåˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶
    if os.path.exists(CHECKPOINT_FILE):
        os.remove(CHECKPOINT_FILE)
        print(f"--- è®­ç»ƒæ£€æŸ¥ç‚¹æ–‡ä»¶ {CHECKPOINT_FILE} å·²åˆ é™¤ ---")


    print("\nç¨‹åºæ‰§è¡Œå®Œæ¯•ã€‚")
